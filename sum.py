import cv2
from gpiozero import DistanceSensor
import RPi.GPIO as GPIO
from face_emotion import get_current_emotion  # ê¸°ì¡´ emotion ëª¨ë“ˆ ì‚¬ìš©
from stt_whispercpp import stt_from_mic
from tts_piper import tts_play
import random, re, time
import threading

# ê²½ëŸ‰ LLM
try:
    from transformers import pipeline
    chat_pipeline = pipeline("text-generation", model="gpt2", device=-1, torch_dtype="float32")
    LLM_AVAILABLE = True
except:
    LLM_AVAILABLE = False
    print("âš ï¸ LLM ë¡œë“œ ì‹¤íŒ¨")

# í•˜ë“œì›¨ì–´ ì„¤ì •
class RobotHardware:
    def __init__(self):
        # Face detection - USB ì¹´ë©”ë¼ë¡œ ë³€ê²½
        self.cascade_path = "/home/sptcnl/haarcascade_frontalface_default.xml"
        self.face_cascade = cv2.CascadeClassifier(self.cascade_path)
        self.cap = cv2.VideoCapture(0)  # USB ì¹´ë©”ë¼ (0ë²ˆ í¬íŠ¸)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        # Distance sensor
        self.distance_sensor = DistanceSensor(echo=21, trigger=4)
        
        # Motor control
        self.left_in3, self.left_in4, self.left_ena = 24, 23, 25
        self.right_in3, self.right_in4, self.right_enb = 18, 17, 27
        
        GPIO.setmode(GPIO.BCM)
        for pin in [self.left_in3, self.left_in4, self.left_ena, 
                   self.right_in3, self.right_in4, self.right_enb]:
            GPIO.setup(pin, GPIO.OUT)
        
        self.left_pwm = GPIO.PWM(self.left_ena, 1000)
        self.right_pwm = GPIO.PWM(self.right_enb, 1000)
        self.left_pwm.start(0)
        self.right_pwm.start(0)
        self.stop()
        
        # ìƒíƒœ ë³€ìˆ˜
        self.is_moving = False
        self.current_speed = 50
        self.current_distance = 0
        self.face_detected = False
        self.running = False
        
    def start_camera(self):
        """USB ì¹´ë©”ë¼ ì‹œìž‘ í™•ì¸"""
        ret, test_frame = self.cap.read()
        if ret:
            print("ðŸ“· USB ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
        else:
            print("âŒ USB ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨! ê½‚í˜€ìžˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    
    def detect_face(self):
        """ì–¼êµ´ ê°ì§€ ë° ê±°ë¦¬ ì¸¡ì • - USB ì¹´ë©”ë¼"""
        ret, frame = self.cap.read()
        if not ret:
            return False, 0, 0
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.2, 5)
        distance = self.distance_sensor.distance * 100
        
        # ì–¼êµ´ì´ ê°ì§€ë˜ë©´ ì „ì§„
        if len(faces) > 0:
            if not self.is_moving:
                self.forward()
                self.set_speed(min(self.current_speed, 40))  # ì•ˆì „ ì†ë„
                self.is_moving = True
            return True, distance, len(faces)
        else:
            if self.is_moving:
                self.stop()
                self.is_moving = False
            return False, distance, 0
    
    # ëª¨í„° ì œì–´ í•¨ìˆ˜ë“¤ (ë³€ê²½ ì—†ìŒ)
    def forward(self):
        GPIO.output(self.left_in3, GPIO.HIGH); GPIO.output(self.left_in4, GPIO.LOW)
        GPIO.output(self.right_in3, GPIO.HIGH); GPIO.output(self.right_in4, GPIO.LOW)
    
    def backward(self):
        GPIO.output(self.left_in3, GPIO.LOW); GPIO.output(self.left_in4, GPIO.HIGH)
        GPIO.output(self.right_in3, GPIO.LOW); GPIO.output(self.right_in4, GPIO.HIGH)
    
    def left_turn(self):
        GPIO.output(self.left_in3, GPIO.LOW); GPIO.output(self.left_in4, GPIO.HIGH)
        GPIO.output(self.right_in3, GPIO.HIGH); GPIO.output(self.right_in4, GPIO.LOW)
    
    def right_turn(self):
        GPIO.output(self.left_in3, GPIO.HIGH); GPIO.output(self.left_in4, GPIO.LOW)
        GPIO.output(self.right_in3, GPIO.LOW); GPIO.output(self.right_in4, GPIO.HIGH)
    
    def stop(self):
        GPIO.output(self.left_in3, GPIO.LOW); GPIO.output(self.left_in4, GPIO.LOW)
        GPIO.output(self.right_in3, GPIO.LOW); GPIO.output(self.right_in4, GPIO.LOW)
        self.left_pwm.ChangeDutyCycle(0)
        self.right_pwm.ChangeDutyCycle(0)
    
    def set_speed(self, speed):
        self.current_speed = speed
        self.left_pwm.ChangeDutyCycle(speed)
        self.right_pwm.ChangeDutyCycle(speed)
    
    def cleanup(self):
        self.stop()
        if self.cap:
            self.cap.release()
        self.left_pwm.stop()
        self.right_pwm.stop()
        cv2.destroyAllWindows()
        GPIO.cleanup()

def local_chat(user_text: str, emotion: str, face_detected: bool, distance: float) -> str:
    if not user_text:
        return "woof woof"
    
    context = f"emotion:{emotion}, face:{'near' if face_detected and distance<100 else 'far'}, distance:{distance:.1f}cm"
    
    if LLM_AVAILABLE:
        try:
            prompt = f"[{context}] User: {user_text}\nRobot (friendly companion robot):"
            response = chat_pipeline(prompt, max_new_tokens=40, do_sample=True)
            reply = response[0]['generated_text'].split("Robot:")[-1].strip()
            return reply[:100]
        except:
            pass
    
    # ìƒí™©ë³„ ë”ë¯¸ ì‘ë‹µ
    if face_detected and distance < 50:
        return "ðŸ¶ ê°€ê¹Œì´ ì™”ì–´! ê°™ì´ ë†€ìž!"
    elif "ì•ˆë…•" in user_text or "hi" in user_text:
        return "ðŸ• ì•ˆë…•í•˜ì„¸ìš” ì£¼ì¸ë‹˜! ðŸ˜Š"
    else:
        responses = {"happy": "ë©‹ì ¸ìš”! ðŸ¾", "sad": "ê´œì°®ì•„ìš”.. ðŸ¥º", "neutral": "ë„¤? ðŸ¶"}
        return responses.get(emotion, f"{user_text} ë“¤ì—ˆì–´ìš”!")

def hardware_monitoring_loop(robot):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§"""
    count = 0
    while robot.running:
        face_detected, distance, face_count = robot.detect_face()
        robot.current_distance = distance
        robot.face_detected = face_detected
        
        count += 1
        print(f"[ðŸ“ {count:4d}] ê±°ë¦¬:{distance:5.1f}cm ì–¼êµ´:{face_count}", end='\r')
        time.sleep(0.1)

def main_loop():
    robot = RobotHardware()
    robot.running = True
    robot.start_camera()
    
    # í•˜ë“œì›¨ì–´ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œìž‘
    monitor_thread = threading.Thread(target=hardware_monitoring_loop, args=(robot,), daemon=True)
    monitor_thread.start()
    
    print("ðŸš€ ë°˜ë ¤ë¡œë´‡ ì‹œìž‘! (ìžë™ ì¶”ì¢… + ìŒì„±ëŒ€í™”)")
    print("Ctrl+Cë¡œ ì¢…ë£Œ")
    
    try:
        while True:
            print("\n=== ìƒˆ ëŒ€í™” ===")
            
            # 1) í•˜ë“œì›¨ì–´ ìƒíƒœ í™•ì¸
            print(f"[ðŸ“¸ ì–¼êµ´]: {'O' if robot.face_detected else 'X'}, [ðŸ“ ê±°ë¦¬]: {robot.current_distance:.1f}cm")
            
            # 2) í‘œì • ê°ì§€ (ê¸°ì¡´ ëª¨ë“ˆ ì‚¬ìš©)
            emotion = get_current_emotion()
            print(f"[ðŸ˜Š ê°ì •]: {emotion}")
            
            # 3) ìŒì„± ìž…ë ¥
            print("ðŸŽ¤ ë§í•´ì¤˜... (10ì´ˆ)")
            text = stt_from_mic(seconds=10)
            print(f"[ðŸ’­ STT]: '{text}'")
            
            # 4) LLM ì‘ë‹µ ìƒì„± (í•˜ë“œì›¨ì–´ ìƒíƒœ í¬í•¨)
            reply = local_chat(text, emotion, robot.face_detected, robot.current_distance)
            print(f"[ðŸ¤– ë¡œë´‡]: {reply}")
            
            # 5) TTS ì¶œë ¥
            tts_play(reply)
            print("-" * 50)
            
    except KeyboardInterrupt:
        print("\nðŸ‘‹ ë¡œë´‡ ì¢…ë£Œ ì¤‘...")
    finally:
        robot.running = False
        robot.cleanup()
        print("âœ… ëª¨ë“  í•˜ë“œì›¨ì–´ ì •ë¦¬ ì™„ë£Œ!")

if __name__ == "__main__":
    main_loop()