import cv2
from face_emotion import get_current_emotion  # fswebcam ë²„ì „
from stt_whispercpp import stt_from_mic
from tts_piper import tts_play
import time
import threading
import RPi.GPIO as GPIO
import gc  # ë©”ëª¨ë¦¬ ê´€ë¦¬ìš©
import subprocess
import os

# BitNetì„ ìœ„í•œ llama-cpp-python ì‚¬ìš© (CPU ì „ìš©)
try:
    from llama_cpp import Llama
    BITNET_MODEL_PATH = "/home/sptcnl/models/bitnet_b1_58-3B.Q4_K_M.gguf"
    chat_model = Llama(
        model_path=BITNET_MODEL_PATH,
        n_ctx=512,
        n_threads=4,
        n_gpu_layers=0,
        verbose=False
    )
    LLM_AVAILABLE = True
    print("âœ… BitNet 3B ë¡œë“œ ì„±ê³µ! (~1GB ë©”ëª¨ë¦¬)")
except Exception as e:
    LLM_AVAILABLE = False
    print(f"âš ï¸ BitNet ë¡œë“œ ì‹¤íŒ¨: {e}")

GPIO.setmode(GPIO.BCM)
servo_pin = 12
GPIO.setup(servo_pin, GPIO.OUT) 
servo = GPIO.PWM(servo_pin, 50)
servo.start(0)
servo_min_duty = 3
servo_max_duty = 12

class RobotHardware:
    def __init__(self):
        self.cascade_path = "/home/sptcnl/haarcascade_frontalface_default.xml"
        self.face_cascade = cv2.CascadeClassifier(self.cascade_path)
        # self.cap ì œê±° - fswebcam ì‚¬ìš©
        self.face_detected = False
        self.running = False
        self.tail_running = False
        self.tail_thread = None
        
    def start_camera(self):
        """fswebcamìœ¼ë¡œ ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸"""
        test_img = self.capture_face_image()
        if test_img:
            print("ğŸ“· fswebcam USB ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
            os.unlink(test_img)  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì‚­ì œ
        else:
            print("âŒ fswebcam ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨! USB ì—°ê²° í™•ì¸í•˜ì„¸ìš”")
    
    def capture_face_image(self):
        """fswebcamìœ¼ë¡œ ë‹¨ì¼ ì´ë¯¸ì§€ ìº¡ì²˜"""
        temp_file = f"/tmp/webcam_face_{int(time.time())}.jpg"
        cmd = [
            "fswebcam",
            "--resolution", "640x480",
            "--no-banner",
            "--save", temp_file
        ]
        try:
            subprocess.run(cmd, check=True, capture_output=True, timeout=3)
            if os.path.exists(temp_file):
                return temp_file
        except:
            pass
        return None
    
    def set_servo_degree(self, degree):
        if degree > 180: degree = 180
        elif degree < 0: degree = 0
        duty = servo_min_duty + (degree * (servo_max_duty - servo_min_duty) / 180.0)
        servo.ChangeDutyCycle(duty)
        time.sleep(0.015)
    
    def tail_wag_loop(self):
        global servo
        while self.tail_running:
            for deg in range(60, 120, 5):
                if not self.tail_running: break
                self.set_servo_degree(deg)
            for deg in range(120, 60, -5):
                if not self.tail_running: break
                self.set_servo_degree(deg)
    
    def start_tail_wag(self):
        if not self.tail_running:
            self.tail_running = True
            self.tail_thread = threading.Thread(target=self.tail_wag_loop, daemon=True)
            self.tail_thread.start()
            print("ğŸ• ê¼¬ë¦¬ í”ë“¤ê¸° ì‹œì‘!")
    
    def stop_tail(self):
        self.tail_running = False
        if self.tail_thread and self.tail_thread.is_alive():
            self.tail_thread.join(timeout=0.1)
        self.set_servo_degree(90)
        print("ğŸ›‘ ê¼¬ë¦¬ ì •ì§€!")
    
    def detect_face(self):
        """fswebcam + OpenCV ì–¼êµ´ ì¸ì‹"""
        img_path = self.capture_face_image()
        if not img_path:
            return False, 0
        
        try:
            frame = cv2.imread(img_path)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.2, 5)
            face_detected = len(faces) > 0
            
            if face_detected and not self.tail_running:
                self.start_tail_wag()
            elif not face_detected and self.tail_running:
                self.stop_tail()
            
            os.unlink(img_path)  # ìº¡ì²˜ ì´ë¯¸ì§€ ì‚­ì œ
            return face_detected, len(faces)
            
        except Exception as e:
            if img_path and os.path.exists(img_path):
                os.unlink(img_path)
            return False, 0
    
    def cleanup(self):
        self.stop_tail()
        cv2.destroyAllWindows()
        servo.ChangeDutyCycle(0)
        servo.stop()
        GPIO.cleanup()
        print("âœ… ëª¨ë“  ì •ë¦¬ ì™„ë£Œ!")

def local_chat(user_text: str, emotion: str, face_detected: bool) -> str:
    if not user_text:
        return "woof woof"
    
    context = f"emotion:{emotion}, face:{'detected' if face_detected else 'not_detected'}"
    
    if LLM_AVAILABLE:
        try:
            prompt = f"[{context}] User: {user_text}\nFriendly robot dog:"
            response = chat_model(
                prompt, 
                max_tokens=50,
                temperature=0.7,
                top_p=0.9,
                stop=["User:", "\n\n"],
                echo=False
            )
            reply = response['choices'][0]['text'].strip()
            gc.collect()
            return reply[:80]
        except Exception as e:
            print(f"LLM ì˜¤ë¥˜: {e}")
            gc.collect()
    
    if face_detected:
        return "ğŸ¶ ì–¼êµ´ ë´¤ì–´! ê°™ì´ ë†€ì!"
    elif "ì•ˆë…•" in user_text or "hi" in user_text:
        return "ğŸ• ì•ˆë…•í•˜ì„¸ìš” ì£¼ì¸ë‹˜! ğŸ˜Š"
    else:
        responses = {"happy": "ë©‹ì ¸ìš”! ğŸ¾", "sad": "ê´œì°®ì•„ìš”.. ğŸ¥º", "neutral": "ë„¤? ğŸ¶"}
        return responses.get(emotion, f"{user_text} ë“¤ì—ˆì–´ìš”!")

def hardware_monitoring_loop(robot):
    count = 0
    while robot.running:
        face_detected, face_count = robot.detect_face()
        robot.face_detected = face_detected
        
        count += 1
        print(f"[ğŸ“¸ {count:4d}] ì–¼êµ´:{face_count} ê¼¬ë¦¬:{'í”ë“¤ë¦¼' if robot.tail_running else 'ì •ì§€'}", end='\r')
        time.sleep(0.5)  # fswebcamì€ ëŠë¦¬ë¯€ë¡œ ê°„ê²© ëŠ˜ë¦¼

def main_loop():
    print("ğŸš€ fswebcam ë°˜ë ¤ë¡œë´‡ ì‹œì‘ ì „ í•„ìˆ˜ í™•ì¸!")
    print("1. sudo apt install fswebcam")
    print("2. USB ì¹´ë©”ë¼ ì—°ê²°")
    print("3. haarcascade_frontalface_default.xml íŒŒì¼ ì¡´ì¬ í™•ì¸")
    
    robot = RobotHardware()
    robot.running = True
    robot.start_camera()
    
    monitor_thread = threading.Thread(target=hardware_monitoring_loop, args=(robot,), daemon=True)
    monitor_thread.start()
    
    print("ğŸš€ BitNet ë°˜ë ¤ë¡œë´‡ ì‹œì‘! (fswebcam ì–¼êµ´ê°ì§€ + ê¼¬ë¦¬í”ë“¤ê¸° + ìŒì„±ëŒ€í™”)")
    print("ğŸ’¾ ë©”ëª¨ë¦¬: htopìœ¼ë¡œ MEM/SWP ëª¨ë‹ˆí„°ë§ ê¶Œì¥")
    print("Ctrl+Cë¡œ ì¢…ë£Œ")
    
    try:
        while True:
            print("\n=== ìƒˆ ëŒ€í™” ===")
            
            print(f"[ğŸ“¸ ì–¼êµ´]: {'O' if robot.face_detected else 'X'} [ğŸ• ê¼¬ë¦¬]: {'í”ë“¤ë¦¼' if robot.tail_running else 'ì •ì§€'}")
            
            emotion = get_current_emotion()  # fswebcam ê¸°ë°˜
            print(f"[ğŸ˜Š ê°ì •]: {emotion}")
            
            print("ğŸ¤ ë§í•´ì¤˜... (10ì´ˆ)")
            text = stt_from_mic(seconds=10)
            print(f"[ğŸ’­ STT]: '{text}'")
            
            reply = local_chat(text, emotion, robot.face_detected)
            print(f"[ğŸ¤– BitNet]: {reply}")
            
            tts_play(reply)
            print("-" * 50)
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ë¡œë´‡ ì¢…ë£Œ ì¤‘...")
    finally:
        robot.running = False
        time.sleep(1.0)  # fswebcam ì •ë¦¬ ëŒ€ê¸°
        robot.cleanup()
        if LLM_AVAILABLE:
            chat_model.free()
            gc.collect()

if __name__ == "__main__":
    main_loop()