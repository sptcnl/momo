from face_emotion import get_current_emotion
from stt_whispercpp import stt_from_mic
from tts_piper import tts_play
import random, re

# ê²½ëŸ‰ LLM (ì²« ì‹¤í–‰ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ ~1GB)
try:
    from transformers import pipeline
    chat_pipeline = pipeline(
        "text-generation",
        model="gpt2",
        device=-1,  # CPU
        torch_dtype="float32"
    )
    LLM_AVAILABLE = True
except:
    LLM_AVAILABLE = False
    print("âš ï¸ LLM ë¡œë“œ ì‹¤íŒ¨. ë”ë¯¸ ì‘ë‹µ ì‚¬ìš©")

def local_chat(user_text: str, emotion: str) -> str:
    if not user_text:
        return "woof woof"
    
    if LLM_AVAILABLE:
        try:
            prompt = f"The user seems {emotion}. The user said: {user_text}\nRobot (friendly tone):"
            response = chat_pipeline(prompt, max_new_tokens=30, do_sample=True)
            reply = response[0]['generated_text'].split("Robot:")[-1].strip()
            return reply[:80]
        except:
            pass
    
    # ë”ë¯¸ ì‘ë‹µ (LLM ì‹¤íŒ¨ì‹œ)
    responses = {
        "happy": "arf arf!",
        "sad": "ruff!",
        "neutral": f"arf!",
        "error": "woof!"
    }
    return responses.get(emotion, f"{user_text} ë“¤ì—ˆì–´!")

def main_loop():
    print("ğŸš€ ë°˜ë ¤ë¡œë´‡ ì‹œì‘! Ctrl+Cë¡œ ì¢…ë£Œ")
    while True:
        print("\n=== ìƒˆ ëŒ€í™” ===")
        
        # 1) í‘œì • ê°ì§€
        emotion = get_current_emotion()
        print(f"[ğŸ“¸ í‘œì •]: {emotion}")
        
        # 2) ìŒì„± ì…ë ¥
        print("ğŸ¤ ë§í•´ì¤˜... (3ì´ˆ)")
        text = stt_from_mic(seconds=10)
        print(f"[ğŸ’­ STT]: '{text}'")
        
        # 3) LLM ì‘ë‹µ
        reply = local_chat(text, emotion)
        print(f"[ğŸ¤– ë¡œë´‡]: {reply}")
        
        # 4) TTS ì¶œë ¥
        tts_play(reply)
        print("-" * 40)

if __name__ == "__main__":
    try:
        main_loop()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ë¡œë´‡ ì¢…ë£Œ!")