import cv2
from face_emotion import get_current_emotion
from stt_whispercpp import stt_from_mic
from tts_piper import tts_play
import time
import threading
import RPi.GPIO as GPIO

try:
    from transformers import pipeline
    chat_pipeline = pipeline("text-generation", model="gpt2", device=-1, torch_dtype="float32")
    LLM_AVAILABLE = True
except:
    LLM_AVAILABLE = False
    print("âš ï¸ LLM ë¡œë“œ ì‹¤íŒ¨")

GPIO.setmode(GPIO.BCM)
servo_pin = 12
GPIO.setup(servo_pin, GPIO.OUT) 
servo = GPIO.PWM(servo_pin, 50)
servo.start(0)
servo_min_duty = 3
servo_max_duty = 12

class RobotHardware:
    def __init__(self):
        self.cascade_path = "/home/sptcnl/haarcascade_frontalface_default.xml"
        self.face_cascade = cv2.CascadeClassifier(self.cascade_path)
        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        self.face_detected = False
        self.running = False
        self.tail_running = False
        self.tail_thread = None
        
    def start_camera(self):
        ret, test_frame = self.cap.read()
        if ret:
            print("ğŸ“· USB ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
        else:
            print("âŒ USB ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨! ê½‚í˜€ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    
    def set_servo_degree(self, degree):
        if degree > 180: degree = 180
        elif degree < 0: degree = 0
        duty = servo_min_duty + (degree * (servo_max_duty - servo_min_duty) / 180.0)
        servo.ChangeDutyCycle(duty)
        time.sleep(0.015)
    
    def tail_wag_loop(self):
        global servo
        while self.tail_running:
            for deg in range(60, 120, 5):
                if not self.tail_running: break
                self.set_servo_degree(deg)
            for deg in range(120, 60, -5):
                if not self.tail_running: break
                self.set_servo_degree(deg)
    
    def start_tail_wag(self):
        if not self.tail_running:
            self.tail_running = True
            self.tail_thread = threading.Thread(target=self.tail_wag_loop, daemon=True)
            self.tail_thread.start()
            print("ğŸ• ê¼¬ë¦¬ í”ë“¤ê¸° ì‹œì‘!")
    
    def stop_tail(self):
        self.tail_running = False
        if self.tail_thread and self.tail_thread.is_alive():
            self.tail_thread.join(timeout=0.1)
        self.set_servo_degree(90)
        print("ğŸ›‘ ê¼¬ë¦¬ ì •ì§€!")
    
    def detect_face(self):
        ret, frame = self.cap.read()
        if not ret:
            return False, 0
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.2, 5)
        face_detected = len(faces) > 0
        
        if face_detected and not self.tail_running:
            self.start_tail_wag()
        elif not face_detected and self.tail_running:
            self.stop_tail()
        
        return face_detected, len(faces)
    
    def cleanup(self):
        self.stop_tail()
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        servo.ChangeDutyCycle(0)
        servo.stop()
        GPIO.cleanup()
        print("âœ… ëª¨ë“  ì •ë¦¬ ì™„ë£Œ!")

def local_chat(user_text: str, emotion: str, face_detected: bool) -> str:
    if not user_text:
        return "woof woof"
    
    context = f"emotion:{emotion}, face:{'detected' if face_detected else 'not_detected'}"
    
    if LLM_AVAILABLE:
        try:
            prompt = f"[{context}] User: {user_text}\nRobot (friendly companion robot):"
            response = chat_pipeline(prompt, max_new_tokens=40, do_sample=True)
            reply = response[0]['generated_text'].split("Robot:")[-1].strip()
            return reply[:100]
        except:
            pass
    
    if face_detected:
        return "ğŸ¶ ì–¼êµ´ ë´¤ì–´! ê°™ì´ ë†€ì!"
    elif "ì•ˆë…•" in user_text or "hi" in user_text:
        return "ğŸ• ì•ˆë…•í•˜ì„¸ìš” ì£¼ì¸ë‹˜! ğŸ˜Š"
    else:
        responses = {"happy": "ë©‹ì ¸ìš”! ğŸ¾", "sad": "ê´œì°®ì•„ìš”.. ğŸ¥º", "neutral": "ë„¤? ğŸ¶"}
        return responses.get(emotion, f"{user_text} ë“¤ì—ˆì–´ìš”!")

def hardware_monitoring_loop(robot):
    count = 0
    while robot.running:
        face_detected, face_count = robot.detect_face()
        robot.face_detected = face_detected
        
        count += 1
        print(f"[ğŸ“¸ {count:4d}] ì–¼êµ´:{face_count} ê¼¬ë¦¬:{'í”ë“¤ë¦¼' if robot.tail_running else 'ì •ì§€'}", end='\r')
        time.sleep(0.1)

def main_loop():
    robot = RobotHardware()
    robot.running = True
    robot.start_camera()
    
    monitor_thread = threading.Thread(target=hardware_monitoring_loop, args=(robot,), daemon=True)
    monitor_thread.start()
    
    print("ğŸš€ ë°˜ë ¤ë¡œë´‡ ì‹œì‘! (ì–¼êµ´ê°ì§€ + ê¼¬ë¦¬í”ë“¤ê¸° + ìŒì„±ëŒ€í™”)")
    print("Ctrl+Cë¡œ ì¢…ë£Œ")
    
    try:
        while True:
            print("\n=== ìƒˆ ëŒ€í™” ===")
            
            print(f"[ğŸ“¸ ì–¼êµ´]: {'O' if robot.face_detected else 'X'} [ğŸ• ê¼¬ë¦¬]: {'í”ë“¤ë¦¼' if robot.tail_running else 'ì •ì§€'}")
            
            emotion = get_current_emotion()
            print(f"[ğŸ˜Š ê°ì •]: {emotion}")
            
            print("ğŸ¤ ë§í•´ì¤˜... (10ì´ˆ)")
            text = stt_from_mic(seconds=10)
            print(f"[ğŸ’­ STT]: '{text}'")
            
            reply = local_chat(text, emotion, robot.face_detected)
            print(f"[ğŸ¤– ë¡œë´‡]: {reply}")
            
            tts_play(reply)
            print("-" * 50)
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ë¡œë´‡ ì¢…ë£Œ ì¤‘...")
    finally:
        robot.running = False
        time.sleep(0.5)
        robot.cleanup()

if __name__ == "__main__":
    main_loop()